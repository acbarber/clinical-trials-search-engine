{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "from whoosh import index\n",
    "from whoosh.index import open_dir\n",
    "from whoosh.fields import Schema, ID, TEXT, STORED\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh.qparser import MultifieldParser\n",
    "from whoosh.query import *\n",
    "import tarfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xml.etree.cElementTree as et\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory: indexdir\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "   os.mkdir(\"indexdir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True))\n",
    "\n",
    "# ix = index.create_in(\"indexdir\", schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
    "# members=tar.getmembers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for member in members:\n",
    "#     tar.extractfile(member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count=0\n",
    "# for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
    "#     for file in files:\n",
    "#         #print os.path.join(subdir, file)\n",
    "#         filepath = subdir + os.sep + file\n",
    "\n",
    "#         if filepath.endswith(\".xml\"):\n",
    "#             count+=1\n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = ix.writer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True))\n",
    "# ix = index.create_in(\"indexdir\", schema)\n",
    "\n",
    "# import xml.etree.cElementTree as et\n",
    "# import codecs\n",
    "\n",
    "# #  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
    "# #  subdirectories. \n",
    "\n",
    "# for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
    "#     for file in files:\n",
    "#         #print os.path.join(subdir, file)\n",
    "#         filepath = subdir + os.sep + file\n",
    "#         parser = et.XMLParser(encoding=\"utf-8\")\n",
    "#         parsedXML = et.parse(filepath)\n",
    "#         def getvalueofnode( node ):\n",
    "#             return node.text if node is not None else None\n",
    "        \n",
    "# #         root=parsedXML.getroot()\n",
    "# #         detailed_description=root.find('detailed_description')\n",
    "        \n",
    "        \n",
    "# #         def get_textblock(nodes):\n",
    "# #             for n in nodes.iter:\n",
    "# #                 if n.tag=='textblock':\n",
    "# #                     return node.text\n",
    "            \n",
    "        \n",
    "        \n",
    "#         for node in parsedXML.getroot():\n",
    "#             url = node.attrib.get('url')\n",
    "#             official_title = node.attrib.get('official_title')\n",
    "#             detailed_description=node.find('detailed_description/textblock')\n",
    "#             writer.add_document(url=url, title=official_title, content= getvalueofnode(detailed_description))\n",
    "# writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema =  Schema(name=ID(stored=True), Title=TEXT(stored=True),content=TEXT(stored=True),gender=TEXT(stored=False),minage=TEXT(stored=False),maxage=TEXT(stored=False))\n",
    "ix = index.create_in(\"indexdir\", schema)\n",
    "writer = ix.writer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traversing through all the files in the directory\n",
    "for j in [b for b in os.listdir(\"clinicaltrials_xml/clinicaltrials_xml/020/\") if b.startswith('0')]:\n",
    "    for k in os.listdir(\"clinicaltrials_xml/clinicaltrials_xml/020/\"+j+\"/\"):\n",
    "        root=et.parse(\"clinicaltrials_xml/clinicaltrials_xml/020/\"+j+\"/\"+k).getroot()\n",
    "#Got the root element now it is time to get into the textbloc of brief_summary and the detail_description\n",
    "        try:\n",
    "            content_text=(root.find('./brief_summary/textblock').text)+(root.find('./detailed_description/textblock').text)\n",
    "        except:\n",
    "            if root.find('./detailed_description/textblock') is None and root.find('./detailed_description/textblock') is None:\n",
    "                content_text=' '\n",
    "            elif root.find('./brief_summary/textblock') is None:\n",
    "                content_text=root.find('./detailed_description/textblock').text\n",
    "            else:\n",
    "                content_text=root.find('./brief_summary/textblock').text\n",
    "\n",
    "        try:\n",
    "            title = (root.find('./brief_title').text)+(root.find('./official_title').text)\n",
    "        except:\n",
    "            if root.find('./brief_title') is None and root.find('./official_title') is None:\n",
    "                title = \" \"\n",
    "            elif root.find('./brief_title') is None:\n",
    "                title = root.find('./official_title').text\n",
    "            else:\n",
    "                title = root.find('./brief_title').text\n",
    "\n",
    "        try:\n",
    "            url=root.find('./required_header/url').text\n",
    "        except:\n",
    "            url=\" \"\n",
    "        try:\n",
    "            if root.find('./eligibility/minimum_age').text=='N/A':\n",
    "                miage=u'0'\n",
    "            else:\n",
    "                miage=root.find('./eligibility/minimum_age').text\n",
    "        except:\n",
    "            miage=u'0'\n",
    "        try:\n",
    "            if root.find('./eligibility/maximum_age').text=='N/A':\n",
    "                maage=u'200'\n",
    "            else:\n",
    "                maage=root.find('./eligibility/maximum_age').text\n",
    "        except:\n",
    "            maage=u'200'\n",
    "        try:\n",
    "            ge=root.find('./eligibility/gender').text\n",
    "        except:\n",
    "            ge=' '\n",
    "#Schema(name=ID(stored=True), Title=TEXT(stored=True),content=TEXT(stored=True),gender=TEXT(stored=True),minage=TEXT(stored=True),maxage=TEXT(stored=True))\n",
    "        writer.add_document(name=url,content=content_text,Title=title,gender=ge,minage=miage,maxage=maage)\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Hit {'Title': 'SARC024: A Blanket Protocol to Study Oral Regorafenib in Patients With Refractory Liposarcoma, Osteogenic Sarcoma, and Ewing SarcomasA Blanket Protocol to Study Oral Regorafenib in Patients With Refractory Liposarcoma, Osteogenic Sarcoma, and Ewing/Ewing-like Sarcomas', 'content': '\\n      Although regorafenib was approved for use in patients who had progressive GIST despite\\n      imatinib and/or sunitinib on the basis of phase II and phase III data, it has not been\\n      examined in a systematic fashion in patients with other forms of sarcoma.\\n\\n      Given the activity of sorafenib, sunitinib and pazopanib in soft tissue sarcomas, and\\n      evidence of activity of sorafenib in osteogenic sarcoma and possibly Ewing/Ewing-like\\n      sarcoma, there is precedent to examine SMOKIs (small molecule oral kinase inhibitors) such\\n      as regorafenib in sarcomas other than GIST. It is also recognized that SMOKIs (small\\n      molecule oral kinase inhibitors)such as regorafenib, sorafenib, pazopanib, and sunitinib\\n      have overlapping panels of kinases that are inhibited simultaneously. While not equivalent,\\n      most of these SMOKIs (small molecule oral kinase inhibitors) block vascular endothelial\\n      growth factor and platelet derived growth factors receptors (VEGFRs and PDGFRs), speaking to\\n      a common mechanism of action of several of these agents.\\n    \\n      Although regorafenib was approved for use in patients who had progressive GIST despite\\n      imatinib and/or sunitinib on the basis of phase II and phase III data, it has not been\\n      examined in a systematic fashion in patients with other forms of sarcoma.\\n\\n      Given the activity of sorafenib, sunitinib and pazopanib in soft tissue sarcomas, and\\n      evidence of activity of sorafenib in osteogenic sarcoma and possibly Ewing/Ewing-like\\n      sarcoma, there is precedent to examine SMOKIs (small molecule oral kinase inhibitors) such\\n      as regorafenib in sarcomas other than GIST. It is also recognized that SMOKIs (small\\n      molecule oral kinase inhibitors)such as regorafenib, sorafenib, pazopanib, and sunitinib\\n      have overlapping panels of kinases that are inhibited simultaneously. While not equivalent,\\n      most of these SMOKIs (small molecule oral kinase inhibitors) block vascular endothelial\\n      growth factor and platelet derived growth factors receptors (VEGFRs and PDGFRs), speaking to\\n      a common mechanism of action of several of these agents\\n    ', 'name': 'https://clinicaltrials.gov/show/NCT02048371'}>, <Hit {'Title': \"A Study to Investigate ALDOXORUBICIN in HIV-infected Subjects With Kaposi's SarcomaAn Open-Label Pilot Phase 2 Study to Investigate Efficacy, Safety, and Intratumoral Kinetics of ALDOXORUBICIN in HIV-Infected Patients With Kaposi's Sarcoma\", 'content': \"\\n      This is a pilot study to determine the efficacy, kinetics and safety of aldoxorubicin in HIV\\n      positive subjects with Kaposi's sarcoma.\\n    \\n      This is an open-label pilot phase 2 study to investigate efficacy, safety, and intratumoral\\n      kinetics of aldoxorubicin in HIV-Infected patients with Kaposi's sarcoma.\\n    \", 'name': 'https://clinicaltrials.gov/show/NCT02029430'}>, <Hit {'Title': 'NY-ESO-1 Specific T Cells After Cyclophosphamide in Treating Patients With Advanced Synovial Sarcoma or Myxoid/Round Cell LiposarcomaA Study to Determine the Feasibility of Treating Synovial Sarcoma and Myxoid/Round Cell Liposarcoma Using Autologous NY-ESO-1 Specific CD8+ T Cells With Cyclophosphamide Pre-conditioning But Without the Use of IL-2', 'content': '\\n      This phase I trial studies the side effects and best way to give NY-ESO-1 specific T cells\\n      after cyclophosphamide in treating patients with advanced synovial sarcoma or myxoid/round\\n      cell liposarcoma. Placing a gene that has been created in the laboratory into white blood\\n      cells may make the body build an immune response to kill tumor cells. Drugs used in\\n      chemotherapy, such as cyclophosphamide, work in different ways to stop the growth of cancer\\n      cells, either by killing the cells or by stopping them from dividing. Giving NY-ESO-1\\n      specific T cells with cyclophosphamide may kill more tumor cells.\\n    \\n      PRIMARY OBJECTIVES:\\n\\n      I. To confirm the safety and efficacy of cancer-testis antigen (NY-ESO-1) specific T cells\\n      (autologous NY-ESO-1-specific cluster of differentiation [CD]8-positive T lymphocytes) in\\n      patients with advanced synovial sarcoma and myxoid/round cell liposarcoma following\\n      conditioning with high dose cyclophosphamide.\\n\\n      SECONDARY OBJECTIVES:\\n\\n      I. To confirm the persistence of NY-ESO-1 tetramer positive cells in the peripheral blood at\\n      10 weeks after T cell infusion for synovial sarcoma and myxoid/round cell liposarcoma\\n      patients receiving NY-ESO-1 specific T cells following cyclophosphamide conditioning but not\\n      post-infusion interleukin (IL)-2.\\n\\n      OUTLINE:\\n\\n      Patients receive cyclophosphamide intravenously (IV) on days -3 and -2 and NY-ESO-1 specific\\n      T cells IV over 60 minutes on day 0. Patients may receive additional infusions at the\\n      discretion of the Principal Investigator (PI).\\n\\n      After completion of study treatment, patients are followed up for up to 12 weeks.\\n    ', 'name': 'https://clinicaltrials.gov/show/NCT02059850'}>, <Hit {'Title': 'Trabectedin First Line Therapy In Unfit Sarcoma StudySAFETY AND ACTIVITY OF TRABECTEDIN AS FIRST LINE IN ADVANCED SOFT TISSUE SARCOMA (STS) PATIENTS UNFIT TO RECEIVE STANDARD CHEMOTHERAPY: A PROSPECTIVE PHASE II STUDY WITH CLINICAL AND MOLECULAR CORRELATES', 'content': '\\n      Phase II, non-randomized, two-stage study according to Bryant & Day The study enroll\\n      patients with Metastatic and locally advanced soft tissue sarcoma unfit to receive standard\\n      chemotherapy (doxorubicin/epirubicin and/or ifosfamide)\\n    \\n      Soft tissue sarcomas are a group of rare and aggressive disease, comprising more than a\\n      hundred different histological subtypes and mainly originating from the embryonic mesoderm.\\n      Today, they represent less than 1% of all adult cancers, with an incidence of 3/100000/year\\n      and a median age at diagnosis of 65 years. Despite the progress done in the last decade,\\n      approximately 50% of STS patients still develop distant metastases within 3 years from the\\n      diagnosis and die from their disease. Doxorubicin (or epirubicin) and ifosfamide have been\\n      proved to be active in the treatment of STS and they are widely used, alone or in\\n      combination, as a first line therapy for locally advanced and metastatic patients. However,\\n      the response rate to the combination regimen in non-pretreated patients does not exceed\\n      30-40%, and large randomized clinical trials failed to demonstrate any advantage in survival\\n      for the combination compared to single-agent treatment. Trabectedin (YondelisÂ®) is a\\n      marine-derived anticancer agent that has been approved in the European Union as a single\\n      agent for the treatment of STS patients after failure of standard chemotherapy (doxorubicin\\n      and/or ifosfamide) or for those unsuited to receive these agents. Even if the response rate\\n      in soft tissue sarcoma does not exceed 10%, trabectedin can provide a significant clinical\\n      benefit, by arresting disease progression in almost 50% of treated patients, with a\\n      progression-free survival rate of 20% at 6 months. Trabectedin was found to be particularly\\n      active in the treatment of myxoid liposarcoma and uterine leiomyosarcoma, for which better\\n      results have been obtained in terms of response rate and survival, suggesting an histotype\\n      driven activity. The toxicity profile of trabectedin given as second line therapy has been\\n      widely assessed in clinical studies and was largely manageable, with the majority of adverse\\n      events being grade 1 or 2 toxicities, generally reversible, dose or time dependent and\\n      noncumulative. The good tolerability profile observed in the trials seems to be confirmed\\n      also in everyday clinical practice. Conversely, few data are available at the moment about\\n      tolerability profile for those patients treated with trabectedin as first line because of\\n      medical conditions contraindicating the use of standard agents. The aim of this phase II\\n      study is to assess and describe trabectedin toxicity profile in this subset of negatively\\n      selected advanced inoperable STS patients.\\n    ', 'name': 'https://clinicaltrials.gov/show/NCT02066675'}>, <Hit {'Title': 'Efficacy of Dose Intensification in Patients With Non-metastatic Ewing SarcomaPhase III Study on Efficacy of Dose Intensification in Patients With Non-metastatic Ewing Sarcoma.', 'content': \"\\n      Controlled, randomized phase III study, with the intent of optimizing the treatment of not\\n      metastatic Ewing Sarcoma. The patients will be randomized into 2 arms: standard treatment vs\\n      intensive treatment. Both arms will receive an induction treatment followed by surgery\\n      (wherever is possible) and/or radiotherapy. The maintenance treatment will be different on\\n      the basis of the response to the induction treatment (good or poor)\\n    \\n      Eligible patients with non metastatic Ewing's Sarcoma will be randomized into 2 different\\n      arms: standard treatment arm A (based on the ISG/SSG III protocol) or into the experimental\\n      arm B(chemotherapy with dose intensification and shorter length of treatment).\\n\\n      Both arm will receive an induction treatment with higher dose intensity of doxorubicin and\\n      ifosfamide in Arm B.\\n\\n      After the induction treatment all the patient will undergo to local treatment (surgery\\n      and/or radiotherapy)that will be followed by a maintenance therapy.\\n\\n      The maintenance therapy will be different for both arms and, within each arm, on the basis\\n      of the response (histologically evaluated) of the pre-local treatment therapy.\\n\\n      Maintenance for Arm A: Poor responders will undergo to stem cells apheresis and their\\n      reinfusion after treatment with high doses of Busulfan and Melphalan 25 weeks.\\n\\n      Good responders will receive a 6 drugs maintenance treatment for 37 weeks (as per standard\\n      ISG/SSG III protocol)\\n\\n      Maintenance for Arm B: Poor responders will undergo to stem cells apheresis and their\\n      reinfusion after an intensified treatment with high doses of Busulfan and Melphalan (25\\n      weeks).\\n\\n      Good responders will receive a maintenance treatment for 25 weeks\\n\\n      The primary aim of the study is to assess the Event Free Survival (EFS) that is expected to\\n      be similar in both arms\\n\\n      The secondary objectives are:\\n\\n      To assess if the induction treatment in Arm B is able to increase the percentage of good\\n      responders compared to those who receive standard treatment.\\n\\n      To assess the toxicity and the Quality of Life related to the chemotherapy treatment\\n    \", 'name': 'https://clinicaltrials.gov/show/NCT02063022'}>, <Hit {'Title': 'Will Glucarpidase After Methotrexate Treatment for Bone Sarcoma Lead to Fewer Side Effects and Reduce Chemotherapy Delays?A Randomised, Cross-over Phase II Study to Investigate the Efficacy and Safety of Glucarpidase for Routine Use After High Dose Methotrexate in Patients With Bone Sarcoma', 'content': '\\n      Methotrexate is one of the most effective chemotherapy drugs in the treatment of\\n      osteosarcoma and some other types of bone sarcoma which are treated the same way as\\n      osteosarcoma. However, it frequently leads to sore mouth, tummy pain and increased risk of\\n      developing infections.\\n\\n      The investigators try to save or \"rescue\" normal cells from the side effects of methotrexate\\n      by giving a drug called folinic acid. Folinic acid is started 24 hours after methotrexate\\n      and given regularly until methotrexate levels are really low and not dangerous to normal\\n      cells anymore. Despite this rescue, side effects are still a problem and many patients are\\n      not well enough to receive subsequent chemotherapy on time. Almost half of the planned\\n      chemotherapy cycles are not given on time due to methotrexate side effects.\\n\\n      In this study the investigators will examine if adding a drug called glucarpidase to folinic\\n      acid is helpful. Glucarpidase is an enzyme that inactivates methotrexate in the blood\\n      stream. Lower methotrexate concentration in the blood stream leads to fewer side effects.\\n      The investigators would like to see if glucarpidase helps patients to have their\\n      chemotherapy on time, by reducing the side effects of methotrexate.\\n    \\n      In this study the patient will receive 4 courses of high-dose methotrexate. High-dose\\n      methotrexate is normally given at weekly intervals, in blocks of two.The first two courses\\n      will be given on weeks 1 & 2; the second two courses on weeks 4 & 5. Two courses will be\\n      given with folinic acid rescue (standard high-dose methotrexate), and the other two will be\\n      given with glucarpidase rescue as well as folinic acid. This will enable us to compare\\n      whether there is any difference in side effects with and without glucarpidase and also how\\n      quickly patients recover from them.\\n\\n      Half of the patients will receive standard high-dose methotrexate on weeks 1 & 2 and\\n      high-dose methotrexate with glucarpidase on weeks 4 & 5 (arm A) and half of the patients\\n      will first have high-dose methotrexate with glucarpidase on weeks 1 & 2 and then standard\\n      high-dose methotrexate on weeks 4 & 5 (arm B).\\n\\n      All patients receiving methotrexate have daily blood tests to monitor the levels of\\n      methotrexate in their body, and monitor their kidney function. However, patients on this\\n      study will have extra blood tests for chemotherapy drug levels and glucarpidase antibody\\n      levels. During each hospital admission for chemotherapy, blood samples will be taken as\\n      follows:\\n\\n      Day 1: Just before starting methotrexate (extra blood test) and at the end of methotrexate\\n      infusion (extra blood test) Day 2: 24 hours after starting methotrexate (routine blood test)\\n      and 20 minutes after the 24-hour blood test (i.e. just after the glucarpidase/placebo\\n      infusion) (extra blood test) Day 3+: Routine daily blood tests until the body has got rid of\\n      the methotrexate Extra blood samples will also be taken 15 days after starting each cycle\\n      and 1 month, 3 and 6 months, after starting the second cycle.\\n\\n      Patients will also be asked to complete mucositis assessment and quality of life\\n      questionnaires.\\n    ', 'name': 'https://clinicaltrials.gov/show/NCT02022358'}>, <Hit {'Title': 'Evaluating Quality of Life in Patients With Soft Tissue Sarcoma Presenting With Metastatic Lung DiseaseEvaluating Quality of Life in Patients With Soft Tissue Sarcoma Presenting With Metastatic Lung Disease Using the ESAS-Sarcoma Modified Questionnaire', 'content': ' ', 'name': 'https://clinicaltrials.gov/show/NCT02080897'}>, <Hit {'Title': 'PP-Gemcitabine & External Beam Radiation-SarcomasA Phase I Study of Preoperative Concomitant Gemcitabine and External-Beam Radiation Therapy and Surgical Resection for Patients With Extremity and Trunk Soft Tissue Sarcomas', 'content': '\\n      The goal of this clinical research study is to find the highest safe dose of gemcitabine\\n      that can be given with radiotherapy before surgery to treat sarcoma. This study will also\\n      look at how well this treatment controls sarcoma.\\n    \\n      Before the start of treatment, participants will have a physical exam, blood tests, a MRI\\n      scan, and a chest x-ray. A PET scan may be done if thought necessary.\\n\\n      Participants will receive the drug gemcitabine by vein along with radiation therapy on Days\\n      1, 8, 22, 29, 43, and 50. Radiation treatments will be given 5 days a week for 5 weeks. The\\n      gemcitabine and radiotherapy will be given on an outpatient basis. Chemotherapy and/or\\n      radiotherapy may be stopped if side effects become severe.\\n\\n      About 4 to 6 weeks after the final dose of gemcitabine, surgery will be done to remove the\\n      tumor or to remove any previous surgical scar and leftover tumor.\\n\\n      During the combined treatment, participants will be seen weekly by the doctor in charge of\\n      radiotherapy or by the study nurse. Blood tests will be done every week during treatment. A\\n      MRI scan and a chest x-ray will be done within 14 days before surgery. A PET scan will be\\n      done if thought necessary.\\n\\n      After the surgery is done, participants will return to M. D. Anderson for follow-up visits\\n      every 4 months for the first 2 years, every 6 months for 3 years, and then yearly from then\\n      on. An ultrasound and MRI scan (of the extremity or trunk) will be done 3 months after\\n      completion of all treatment. Ultrasound scans will be performed at each visit. A MRI scan\\n      will only be done again at later visits if needed.\\n\\n      This is an investigational study. Gemcitabine is approved for use by the FDA. Its use\\n      together with radiation therapy in this study is experimental. About 36 individuals will\\n      take part in the study. All will be enrolled at M. D. Anderson.\\n    ', 'name': 'https://clinicaltrials.gov/show/NCT02046304'}>, <Hit {'Title': 'Sorafenib Tosylate, Combination Chemotherapy, Radiation Therapy, and Surgery in Treating Patients With High-Risk Stage IIB-IV Soft Tissue SarcomaA Phase II Study of Sorafenib With Chemotherapy, Radiation, and Surgery for High-Risk Soft Tissue Sarcomas', 'content': '\\n      This phase II trial studies how well sorafenib tosylate, combination chemotherapy, radiation\\n      therapy, and surgery work in treating patients with high-risk stage IIB-IV soft tissue\\n      sarcoma. Sorafenib tosylate may stop the growth of tumor cells by blocking some of the\\n      enzymes needed for cell growth. Drugs used in chemotherapy, such as epirubicin hydrochloride\\n      and ifosfamide, work in different ways to stop the growth of tumor cells, either by killing\\n      the cells, by stopping them from dividing, or by stopping them from spreading. Radiation\\n      therapy uses high energy x rays to kill tumor cells. Giving sorafenib tosylate, combination\\n      chemotherapy, radiation therapy, and surgery may be an effective treatment for soft tissue\\n      sarcoma.\\n    \\n      PRIMARY OBJECTIVES:\\n\\n      I. To determine the pathologic response rate (>= 95% necrosis) after preoperative treatment\\n      with sorafenib (sorafenib tosylate), epirubicin (epirubicin hydrochloride), ifosfamide, and\\n      hypofractionated radiation for high risk soft tissue sarcomas of the extremities or body\\n      wall.\\n\\n      SECONDARY OBJECTIVES:\\n\\n      I. To further characterize the safety of sorafenib plus chemoradiotherapy, including wound\\n      complication rate.\\n\\n      II. To estimate time-to-event rates, including overall survival, overall disease-free\\n      survival, distant disease-free survival, and local disease-free survival in patients with\\n      high risk soft tissue sarcomas of the extremities or body wall treated with preoperative\\n      sorafenib plus chemoradiotherapy and postoperative sorafenib plus chemotherapy.\\n\\n      OUTLINE:\\n\\n      Patients receive sorafenib tosylate orally (PO) once daily (QD) on days 1-71 and 85-155,\\n      epirubicin hydrochloride intravenously (IV) over 3-5 minutes, and ifosfamide IV over 90\\n      minutes on days 15-17, 36-38 (ifosfamide only), 57-59, 99-101, 120-122, and 141-143.\\n      Patients undergo external beam radiation therapy (EBRT) on days 36-45 and surgical resection\\n      on day 78. Patients with positive margins, undergo EBRT boost on days 91-98.\\n\\n      After completion of study treatment, patients are followed up every 4 months for 2 years,\\n      every 6 months for 1 year, and then yearly for 2 years.\\n    ', 'name': 'https://clinicaltrials.gov/show/NCT02050919'}>, <Hit {'Title': 'SARC023: Ganetespib and Sirolimos in Patients With MPNST (Malignant Peripheral Nerve Sheath Tumors)A Phase I/II Trial of Ganetespib in Combination With the mTOR Inhibitor Sirolimus for Patients With Recurrent or Refractory Sarcomas Including Unresectable or Metastatic Malignant Peripheral Nerve Sheath Tumors', 'content': \"\\n      Phase 1: To assess the safety, tolerability, and maximum tolerated dose (MTD)/ recommended\\n      dose of ganetespib when administered in combination with sirolimus in patients with\\n      refractory or relapsed sarcomas including unresectable or metastatic sporadic or\\n      neurofibromatosis type 1 (NF1) associated MPNST. Phase I enrollment has been closed.\\n\\n      Phase 2: To determine the clinical benefit of ganetespib in combination with sirolimus for\\n      patients with unresectable or metastatic sporadic or NF1 associated MPNST.\\n    \\n      Previously, no targeted agents have been able to cause tumor regression in a genetically\\n      engineered MPNST mouse model or human MPNST. Recently published data from Dr. Cichowski's\\n      laboratory demonstrated using Hsp90 inhibitors to enhance endoplasmic reticulum stress\\n      coupled with the mammalian target of rapamycin (mTOR) inhibitor sirolimus led to dramatic\\n      tumor shrinkage in a transgenic MPNST mouse model, which correlated with profound damage to\\n      the endoplasmic reticulum and cell death. Ganetespib is a novel, injectable, small molecule\\n      inhibitor of Hsp90 and is currently being investigated in adults with a broad range of tumor\\n      types with a favorable safety profile and promising early results. Ganetespib has been\\n      studied in preclinical in vivo models with a variety of targeted agents with no marked\\n      apparent pharmacological interactions. Sirolimus is a commercially available orally\\n      administered mTOR inhibitor and is the active metabolite of temsirolimus, which is FDA\\n      approved agent for advanced metastatic renal cell carcinoma. Sirolimus has been studied and\\n      tolerated in combination with multiple cytotoxic and targeted agents in a variety of tumor\\n      types. Based on strong preclinical rationale, the investigators hypothesize that ganetespib\\n      in combination with sirolimus will cause tumor regression in patients with refractory\\n      MPNSTs.\\n\\n      The investigators propose a multi-institutional open label phase I/II trial of ganetespib in\\n      combination with sirolimus in patients with refractory sarcoma including MPNST. Hsp90\\n      inhibitors and mTOR inhibitors have also both demonstrated benefit in a variety of\\n      preclinical bone and soft tissue sarcoma models. The investigators hypothesize that these\\n      agents that work on separate and potentially synergistic pathways will also be beneficial\\n      for other refractory bone and soft tissue sarcomas. Thus, the phase I component will be open\\n      to patients with refractory sarcomas, which will also expedite enrollment. Upon\\n      determination of the recommended dosing, a phase II study will be conducted. The phase II\\n      study population will be limited to patients with a diagnosis of MPNST.\\n    \", 'name': 'https://clinicaltrials.gov/show/NCT02008877'}>]\n"
     ]
    }
   ],
   "source": [
    "ix = open_dir(\"indexdir\")\n",
    "qp = MultifieldParser([\"content\",'Title'], schema =ix.schema)\n",
    "q = qp.parse(u\"sarcoma\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    results = s.search(q, limit=10)\n",
    "    print(results[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SARC024: A Blanket Protocol to Study Oral Regorafenib in Patients With Refractory Liposarcoma, Osteogenic Sarcoma, and Ewing SarcomasA Blanket Protocol to Study Oral Regorafenib in Patients With Refractory Liposarcoma, Osteogenic Sarcoma, and Ewing/Ewing-like Sarcomas', 'https://clinicaltrials.gov/show/NCT02048371', '\\n      Although regorafenib was approved for use in patients who had progressive GIST despite\\n      imatinib and/or sunitinib on the basis of phase II and phase III data, it has not been\\n      examined in a systematic fashion in patients with other forms of sarcoma.\\n\\n      Given the activity of sorafenib, sunitinib and pazopanib in soft tissue sarcomas, and\\n      evidence of activity of sorafenib in osteogenic sarcoma and possibly Ewing/Ewing-like\\n      sarcoma, there is precedent to examine SMOKIs (small molecule oral kinase inhibitors) such\\n      as regorafenib in sarcomas other than GIST. It is also recognized that SMOKIs (small\\n      molecule oral kinase inhibitors)such as regorafenib, sorafenib, pazopanib, and sunitinib\\n      have overlapping panels of kinases that are inhibited simultaneously. While not equivalent,\\n      most of these SMOKIs (small molecule oral kinase inhibitors) block vascular endothelial\\n      growth factor and platelet derived growth factors receptors (VEGFRs and PDGFRs), speaking to\\n      a common mechanism of action of several of these agents.\\n    \\n      Although regorafenib was approved for use in patients who had progressive GIST despite\\n      imatinib and/or sunitinib on the basis of phase II and phase III data, it has not been\\n      examined in a systematic fashion in patients with other forms of sarcoma.\\n\\n      Given the activity of sorafenib, sunitinib and pazopanib in soft tissue sarcomas, and\\n      evidence of activity of sorafenib in osteogenic sarcoma and possibly Ewing/Ewing-like\\n      sarcoma, there is precedent to examine SMOKIs (small molecule oral kinase inhibitors) such\\n      as regorafenib in sarcomas other than GIST. It is also recognized that SMOKIs (small\\n      molecule oral kinase inhibitors)such as regorafenib, sorafenib, pazopanib, and sunitinib\\n      have overlapping panels of kinases that are inhibited simultaneously. While not equivalent,\\n      most of these SMOKIs (small molecule oral kinase inhibitors) block vascular endothelial\\n      growth factor and platelet derived growth factors receptors (VEGFRs and PDGFRs), speaking to\\n      a common mechanism of action of several of these agents\\n    ')\n"
     ]
    }
   ],
   "source": [
    "cancer='sarcoma'\n",
    "gene='cdk4'\n",
    "\n",
    "query_b = MultifieldParser(['Title','content'], ix.schema).parse('{} OR {}'.format(cancer, gene))\n",
    "with ix.searcher() as srch:\n",
    "    res_b = srch.search(query_b, limit=20)\n",
    "    results=[(i['Title'],i['name'],i['content']) for i in res_b]\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='clinicaltrials.xml/clinicaltrials_xml/020/02000/NCT02000011.xml'\n",
    "\n",
    "parser = et.XMLParser(encoding=\"utf-8\")\n",
    "parsedXML = et.parse(filepath, parser=parser)\n",
    "for node in parsedXML.getroot():\n",
    "    d=node.findall('detailed_description')\n",
    "    for text in d:\n",
    "        t=text.find('textblock')\n",
    "        print(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<clinical_study rank=\"84899\">\n",
      "  <!-- This xml conforms to an XML Schema at:\n",
      "    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->\n",
      "  <required_header>\n",
      "    <download_date>ClinicalTrials.gov processed this data on April 10, 2017</download_date>\n",
      "    <link_text>Link to the current ClinicalTrials.gov record.</link_text>\n",
      "    <url>https://clinicaltrials.gov/show/NCT02000011</url>\n",
      "  </required_header>\n",
      "  <id_info>\n",
      "    <org_study_id>2013-A01038-37</org_study_id>\n",
      "    <secondary_id>2013-33</secondary_id>\n",
      "    <nct_id>NCT02000011</nct_id>\n",
      "  </id_info>\n",
      "  <brief_title>Interest of a Geriatric Intervention Plan Associated to a Comprehensive Geriatric Assessment on Autonomy, Quality of Life and Survival of Patients Aged 70 Years Old and More Surgically Treated for a Resectable Cancer (Thoracic, Digestive or Urologic). Randomized Multicentric Study</brief_title>\n",
      "  <acronym>epigac</acronym>\n",
      "  <official_title>Interest of a Geriatric Intervention Plan Associated to a Comprehensive Geriatric Assessment on Autonomy, Quality of Life and Survival of Patients Aged 70 Years Old and More Surgically Treated for a Resectable Cancer (Thoracic, Digestive or Urologic). Randomized Multicentric Study</official_title>\n",
      "  <sponsors>\n",
      "    <lead_sponsor>\n",
      "      <agency>Assistance Publique Hopitaux De Marseille</agency>\n",
      "      <agency_class>Other</agency_class>\n",
      "    </lead_sponsor>\n",
      "  </sponsors>\n",
      "  <source>Assistance Publique Hopitaux De Marseille</source>\n",
      "  <oversight_info>\n",
      "    <has_dmc>No</has_dmc>\n",
      "  </oversight_info>\n",
      "  <brief_summary>\n",
      "    <textblock>\n",
      "      The curative treatment of thoracic (lung and oesophagus), digestive (gastric, pancreatic,\n",
      "      hepatic, colorectal), and urologic (renal, bladder, prostatic) cancers needs a surgical\n",
      "      resection. For patients aged of 70 years old and more, this surgery is associated to an\n",
      "      increased morbid-mortality especially because of more frequent co-morbidities. Comprehensive\n",
      "      geriatric assessment (CGA) allows distinguishing patients for whom a resection surgery can\n",
      "      be complicated by high morbid-mortality or a loss of autonomy. It has been proved that for\n",
      "      old patient population without cancer, CGA associated with a geriatric intervention plan\n",
      "      (GIP) allows autonomy preservation, decrease of institution admission, and survival\n",
      "      improvement. The reference study showed that a CGA associated to a GIP improves survival of\n",
      "      old patients who had a cancer surgery. However this study included patients from 60 years\n",
      "      old and the GIP consisted in 3 home visits and 5 phone calls during the 4 weeks following\n",
      "      hospital discharge.\n",
      "\n",
      "      We propose to perform a prospective and randomized study to evaluate the impact of a CGA\n",
      "      with GIP in 70 years old and more patients with a thoracic, digestive or urologic cancer\n",
      "      resection, respectively 1, 3, 6 and 12 months after discharge. CGA and GIP will focus on 8\n",
      "      distinct fields: autonomy, co-morbidities, co-medication, mobility, nutritional status,\n",
      "      depression, cognitive function and social status. The impact of such a strategy on autonomy\n",
      "      and survival has never been studied.\n",
      "    </textblock>\n",
      "  </brief_summary>\n",
      "  <overall_status>Recruiting</overall_status>\n",
      "  <start_date>December 2013</start_date>\n",
      "  <completion_date type=\"Anticipated\">May 2018</completion_date>\n",
      "  <primary_completion_date type=\"Anticipated\">November 2017</primary_completion_date>\n",
      "  <phase>N/A</phase>\n",
      "  <study_type>Interventional</study_type>\n",
      "  <has_expanded_access>No</has_expanded_access>\n",
      "  <study_design_info>\n",
      "    <allocation>Randomized</allocation>\n",
      "    <intervention_model>Parallel Assignment</intervention_model>\n",
      "    <primary_purpose>Supportive Care</primary_purpose>\n",
      "    <masking>Open Label</masking>\n",
      "  </study_design_info>\n",
      "  <primary_outcome>\n",
      "    <measure>the 6-month autonomy after surgery</measure>\n",
      "    <time_frame>24 MONTHS</time_frame>\n",
      "  </primary_outcome>\n",
      "  <secondary_outcome>\n",
      "    <measure>12-month autonomy</measure>\n",
      "    <time_frame>48 months</time_frame>\n",
      "  </secondary_outcome>\n",
      "  <number_of_arms>2</number_of_arms>\n",
      "  <enrollment type=\"Anticipated\">380</enrollment>\n",
      "  <condition>Cancer</condition>\n",
      "  <arm_group>\n",
      "    <arm_group_label>standard strategy</arm_group_label>\n",
      "    <arm_group_type>Other</arm_group_type>\n",
      "  </arm_group>\n",
      "  <arm_group>\n",
      "    <arm_group_label>experimental strategy</arm_group_label>\n",
      "    <arm_group_type>Experimental</arm_group_type>\n",
      "  </arm_group>\n",
      "  <intervention>\n",
      "    <intervention_type>Other</intervention_type>\n",
      "    <intervention_name>comprehensive geriatric assessment (CGA)</intervention_name>\n",
      "    <arm_group_label>standard strategy</arm_group_label>\n",
      "    <arm_group_label>experimental strategy</arm_group_label>\n",
      "  </intervention>\n",
      "  <intervention>\n",
      "    <intervention_type>Other</intervention_type>\n",
      "    <intervention_name>Geriatric intervention plan (GIP)</intervention_name>\n",
      "    <arm_group_label>experimental strategy</arm_group_label>\n",
      "  </intervention>\n",
      "  <eligibility>\n",
      "    <criteria>\n",
      "      <textblock>\n",
      "        Inclusion Criteria:\n",
      "\n",
      "          -  Male or female aged 70 years old or more\n",
      "\n",
      "          -  Patient with a resectable cancer( thoracic, digestive ore urologic);\n",
      "\n",
      "          -  Patients who have to undergo a surgery with general anaesthesia;\n",
      "\n",
      "          -  Patients treated in one of the partner programme unit ;\n",
      "\n",
      "          -  Patient able to fill in an auto-questionnaire alone or with some help;\n",
      "\n",
      "          -  Patient who have signed an informed consent and who commits himself or herself to\n",
      "             respect the protocol instructions.\n",
      "\n",
      "        Exclusion Criteria:\n",
      "\n",
      "          -  Patient younger than 70 years old;\n",
      "\n",
      "          -  Patient who is not registered to the social ;\n",
      "\n",
      "          -  Patient for whom surgery is performed under local anaesthesia;\n",
      "\n",
      "          -  Patient unable to fill-in alone an autoquestionnaire (because of an inability to read\n",
      "             French language or severe cognitive troubles);\n",
      "\n",
      "          -  Patient treated with neuroleptic or lithium ;\n",
      "\n",
      "          -  Patient with already known cognitive impairment (Alzheimer, dementia, neurologic\n",
      "             sequel);\n",
      "\n",
      "          -  Patient under legal protection;\n",
      "\n",
      "          -  Patient who has not signed informed consent.\n",
      "      </textblock>\n",
      "    </criteria>\n",
      "    <gender>All</gender>\n",
      "    <minimum_age>70 Years</minimum_age>\n",
      "    <maximum_age>N/A</maximum_age>\n",
      "    <healthy_volunteers>No</healthy_volunteers>\n",
      "  </eligibility>\n",
      "  <overall_official>\n",
      "    <last_name>LOIC MONDOLONI</last_name>\n",
      "    <role>Study Director</role>\n",
      "    <affiliation>Assistance Publique Hopitaux De Marseille</affiliation>\n",
      "  </overall_official>\n",
      "  <overall_contact>\n",
      "    <last_name>vincent moutardier</last_name>\n",
      "    <email>vincent.moutardier@ap-hm.fr</email>\n",
      "  </overall_contact>\n",
      "  <location>\n",
      "    <facility>\n",
      "      <name>Assistance Publique Hopitaux de Marseille</name>\n",
      "      <address>\n",
      "        <city>Marseille</city>\n",
      "        <zip>13354</zip>\n",
      "        <country>France</country>\n",
      "      </address>\n",
      "    </facility>\n",
      "    <status>Recruiting</status>\n",
      "    <contact>\n",
      "      <last_name>vincent moutardier</last_name>\n",
      "      <email>vincent.moutardier@ap-hm.fr</email>\n",
      "    </contact>\n",
      "    <investigator>\n",
      "      <last_name>vincent moutardier</last_name>\n",
      "      <role>Principal Investigator</role>\n",
      "    </investigator>\n",
      "  </location>\n",
      "  <location_countries>\n",
      "    <country>France</country>\n",
      "  </location_countries>\n",
      "  <verification_date>July 2016</verification_date>\n",
      "  <lastchanged_date>July 6, 2016</lastchanged_date>\n",
      "  <firstreceived_date>November 26, 2013</firstreceived_date>\n",
      "  <responsible_party>\n",
      "    <responsible_party_type>Sponsor</responsible_party_type>\n",
      "  </responsible_party>\n",
      "  <keyword>patients</keyword>\n",
      "  <keyword>aged 70 years old</keyword>\n",
      "  <keyword>thoracic,</keyword>\n",
      "  <keyword>digestive or</keyword>\n",
      "  <keyword>urological</keyword>\n",
      "  <keyword>resectable</keyword>\n",
      "  <!-- Results have not yet been posted for this study                                -->\n",
      "</clinical_study>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('clinicaltrials.xml/clinicaltrials_xml/020/02000/NCT02000011.xml', 'r') as f:\n",
    "    h=f.read()\n",
    "    f.close()\n",
    "\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os, os.path\n",
      "from whoosh import index\n",
      "from whoosh.index import open_dir\n",
      "from whoosh.fields import Schema, ID, TEXT, STORED\n",
      "from whoosh.qparser import QueryParser\n",
      "from whoosh.query import *\n",
      "import tarfile\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os, os.path\n",
      "from whoosh import index\n",
      "from whoosh.index import open_dir\n",
      "from whoosh.fields import Schema, ID, TEXT, STORED\n",
      "from whoosh.qparser import QueryParser\n",
      "from whoosh.query import *\n",
      "import tarfile\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "if not os.path.exists(\"indexdir\"):\n",
      "   os.mkdir(\"indexdir\")\n",
      "schema =  Schema(url=ID(stored=True), title=STORED, content=TEXT)\n",
      "ix = index.create_in(\"indexdir\", schema)\n",
      "writer = ix.writer()\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "count=0\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "\n",
      "        if filepath.endswith(\".xml\"):\n",
      "            count+=1\n",
      "count\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse( filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=schema)\n",
      "q = qp.parse(\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=schema)\n",
      "q = qp.parse(\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=schema)\n",
      "q = qp.parse(\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=schema)\n",
      "q = qp.parse(\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search('cancer')\n",
      "results\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=schema)\n",
      "q = qp.parse(\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(ix.\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir/MAIN.tmp\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "if not os.path.exists(\"indexdir2\"):\n",
      "   os.mkdir(\"indexdir2\")\n",
      "schema =  Schema(url=ID(stored=True), title=STORED, content=TEXT)\n",
      "ix = index.create_in(\"indexdir2\", schema)\n",
      "writer = ix.writer()\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "count=0\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "\n",
      "        if filepath.endswith(\".xml\"):\n",
      "            count+=1\n",
      "count\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse( filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix.schema\n",
      "from whoosh.query import Every\n",
      "results = ix.searcher().search(Every('content'))\n",
      "from whoosh.query import Every\n",
      "results = ix.searcher().search(Every('content'))\n",
      "results[0]\n",
      "from whoosh.qparser import QueryParser\n",
      "from whoosh.qparser import FuzzyTermPlugin\n",
      "from whoosh.index import open_dir\n",
      "import codecs\n",
      "\n",
      "#now that we have an index, we can open it with open_dir\n",
      "ix = open_dir(\"indexdir2\")\n",
      "\n",
      "phrase_to_search = unicode(\"swallow\")\n",
      "\n",
      "with ix.searcher() as searcher: \n",
      "    parser = QueryParser(\"content\", schema=ix.schema)\n",
      "\n",
      "    query = parser.parse( phrase_to_search )\n",
      "    results = searcher.search(query)\n",
      "\n",
      "    for hit in results:    \n",
      "        hit_encoding = (hit[\"encoding\"])\n",
      "\n",
      "        with codecs.open(hit[\"path\"], \"r\", hit_encoding) as fileobj:\n",
      "            filecontents  = fileobj.read()\n",
      "            hit_highlight = hit.highlights(\"content\", text=filecontents)\n",
      "            hit_title     = (hit[\"title\"])\n",
      "\n",
      "            print type(hit_highlight), hit[\"title\"]\n",
      "from whoosh.qparser import QueryParser\n",
      "from whoosh.qparser import FuzzyTermPlugin\n",
      "from whoosh.index import open_dir\n",
      "import codecs\n",
      "\n",
      "#now that we have an index, we can open it with open_dir\n",
      "ix = open_dir(\"indexdir2\")\n",
      "\n",
      "phrase_to_search = unicode(\"swallow\")\n",
      "\n",
      "with ix.searcher() as searcher: \n",
      "    parser = QueryParser(\"content\", schema=ix.schema)\n",
      "\n",
      "    query = parser.parse( phrase_to_search )\n",
      "    results = searcher.search(query)\n",
      "\n",
      "    for hit in results:    \n",
      "        hit_encoding = (hit[\"encoding\"])\n",
      "\n",
      "        with codecs.open(hit[\"path\"], \"r\", hit_encoding) as fileobj:\n",
      "            filecontents  = fileobj.read()\n",
      "            hit_highlight = hit.highlights(\"content\", text=filecontents)\n",
      "            hit_title     = (hit[\"title\"])\n",
      "\n",
      "            print (type(hit_highlight), hit[\"title\"])\n",
      "from whoosh.qparser import QueryParser\n",
      "from whoosh.qparser import FuzzyTermPlugin\n",
      "from whoosh.index import open_dir\n",
      "import codecs\n",
      "\n",
      "#now that we have an index, we can open it with open_dir\n",
      "ix = open_dir(\"indexdir2\")\n",
      "\n",
      "phrase_to_search = u\"swallow\"\n",
      "\n",
      "with ix.searcher() as searcher: \n",
      "    parser = QueryParser(\"content\", schema=ix.schema)\n",
      "\n",
      "    query = parser.parse( phrase_to_search )\n",
      "    results = searcher.search(query)\n",
      "\n",
      "    for hit in results:    \n",
      "        hit_encoding = (hit[\"encoding\"])\n",
      "\n",
      "        with codecs.open(hit[\"path\"], \"r\", hit_encoding) as fileobj:\n",
      "            filecontents  = fileobj.read()\n",
      "            hit_highlight = hit.highlights(\"content\", text=filecontents)\n",
      "            hit_title     = (hit[\"title\"])\n",
      "\n",
      "            print (type(hit_highlight), hit[\"title\"])\n",
      "from whoosh.qparser import QueryParser\n",
      "from whoosh.qparser import FuzzyTermPlugin\n",
      "from whoosh.index import open_dir\n",
      "import codecs\n",
      "\n",
      "#now that we have an index, we can open it with open_dir\n",
      "ix = open_dir(\"indexdir2\")\n",
      "\n",
      "phrase_to_search = u\"cancer\"\n",
      "\n",
      "with ix.searcher() as searcher: \n",
      "    parser = QueryParser(\"content\", schema=ix.schema)\n",
      "\n",
      "    query = parser.parse( phrase_to_search )\n",
      "    results = searcher.search(query)\n",
      "\n",
      "    for hit in results:    \n",
      "        hit_encoding = (hit[\"encoding\"])\n",
      "\n",
      "        with codecs.open(hit[\"path\"], \"r\", hit_encoding) as fileobj:\n",
      "            filecontents  = fileobj.read()\n",
      "            hit_highlight = hit.highlights(\"content\", text=filecontents)\n",
      "            hit_title     = (hit[\"title\"])\n",
      "\n",
      "            print (type(hit_highlight), hit[\"title\"])\n",
      "schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT)\n",
      "ix = index.create_in(\"indexdir2\", schema)\n",
      "if not os.path.exists(\"indexdir2\"):\n",
      "   os.mkdir(\"indexdir2\")\n",
      "schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT)\n",
      "ix = index.create_in(\"indexdir2\", schema)\n",
      "writer = ix.writer()\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "count=0\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "\n",
      "        if filepath.endswith(\".xml\"):\n",
      "            count+=1\n",
      "count\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse( filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse( 'u'+filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse( 'u'+filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse( 'u'+filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse( unicode(filepath), parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00200/NCT0200005', 'r') as f:\n",
      "    f.read()\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00200/NCT0200005.xml', 'r') as f:\n",
      "    f.read()\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml', 'r') as f:\n",
      "    f.read()\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00200', 'r') as f:\n",
      "    f.read()\n",
      "    f.close()\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00200/NCT00200005.xml', 'r') as f:\n",
      "    f.read()\n",
      "    f.close()\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00200/NCT00200005.xml', 'r') as f:\n",
      "    f.read()\n",
      "    f.close()\n",
      "    print(f)\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00200/NCT00200005.xml', 'r') as f:\n",
      "    h=f.read()\n",
      "    f.close()\n",
      "    print(h)\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00200/NCT00200018.xml', 'r') as f:\n",
      "    h=f.read()\n",
      "    f.close()\n",
      "    print(h)\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00200/NCT00200291.xml', 'r') as f:\n",
      "    h=f.read()\n",
      "    f.close()\n",
      "    print(h)\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00200/NCT00200356.xml', 'r') as f:\n",
      "    h=f.read()\n",
      "    f.close()\n",
      "    print(h)\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00280/NCT00280644.xml', 'r') as f:\n",
      "    h=f.read()\n",
      "    f.close()\n",
      "    print(h)\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00280/NCT00280787.xml', 'r') as f:\n",
      "    h=f.read()\n",
      "    f.close()\n",
      "    print(h)\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "from whoosh.qparser import QueryParser\n",
      "from whoosh.qparser import FuzzyTermPlugin\n",
      "from whoosh.index import open_dir\n",
      "import codecs\n",
      "\n",
      "#now that we have an index, we can open it with open_dir\n",
      "ix = open_dir(\"indexdir2\")\n",
      "\n",
      "phrase_to_search = u\"cancer\"\n",
      "\n",
      "with ix.searcher() as searcher: \n",
      "    parser = QueryParser(\"content\", schema=ix.schema)\n",
      "\n",
      "    query = parser.parse( phrase_to_search )\n",
      "    results = searcher.search(query)\n",
      "\n",
      "    for hit in results:    \n",
      "        hit_encoding = (hit[\"encoding\"])\n",
      "\n",
      "        with codecs.open(hit[\"path\"], \"r\", hit_encoding) as fileobj:\n",
      "            filecontents  = fileobj.read()\n",
      "            hit_highlight = hit.highlights(\"content\", text=filecontents)\n",
      "            hit_title     = (hit[\"title\"])\n",
      "\n",
      "            print (type(hit_highlight), hit[\"title\"])\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + ufile\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + \"u\"file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + \"u\"+file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + \"u\",file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse('u'filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse('u'+filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(ufilepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + u+file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + u+str(file)\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + ufile\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "\n",
      "for subdir, dirs, files in os.walk(u'clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        f=codecs.open(file, 'r', encoding='utf-8')\n",
      "        filepath = subdir + os.sep + f\n",
      "        f.close()\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        \n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url').text.encode('utf-8')\n",
      "            official_title = node.find('official_title').text.encode('utf-8')\n",
      "            textblock = node.find('textblock').text.encode('utf-8')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        \n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title').text.encode('utf-8')\n",
      "            textblock = node.find('textblock').text.encode('utf-8')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        \n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(u+filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        \n",
      "        filepath = subdir + os.sep + (u+file)\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        \n",
      "        filepath = subdir + os.sep + ('u'+file)\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        \n",
      "        filepath = usubdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        \n",
      "        filepath = 'u'subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        \n",
      "        filepath = 'u'+subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file=u+str(file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file=ustr(file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file= u'file'\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files.decode('utf-8'):\n",
      "        #print os.path.join(subdir, file)\n",
      "        file= \n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file= \n",
      "        filepath = subdir + os.sep + file.decode('utf-8')\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file= \n",
      "        filepath = subdir + os.sep + file.decode('utf-8')\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file= \n",
      "        filepath = subdir + os.sep + (file.decode('utf-8'))\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file= \n",
      "        filepath = subdir + os.sep + (file.decode('utf-8'))\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002').decode('utf-8'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file= \n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002').decode('utf-8'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file.decode('utf-8')\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files.decode('utf-8'):\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002').decode('utf-8'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'.decode('utf-8')):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir.decode('utf-8') + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir.decode('utf-8'), dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files.decode('utf-8'):\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "dir='clinicaltrials.xml/clinicaltrials_xml/002'.decode('utf-8')\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk(unicode('clinicaltrials.xml/clinicaltrials_xml/002')):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for uicode(file) in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for  in unicode(files):\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for  in unicode(files):\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in unicode(files):\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file=unicode(file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file=fild.decode('utf-8')\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        file=file.decode('utf-8')\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results[0]\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"cancer\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results[0]\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "    print(results[0])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "    print(results[1])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "    results\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "    print(results)\n",
      "from whoosh.qparser import QueryParser\n",
      "from whoosh.qparser import FuzzyTermPlugin\n",
      "from whoosh.index import open_dir\n",
      "import codecs\n",
      "\n",
      "#now that we have an index, we can open it with open_dir\n",
      "ix = open_dir(\"indexdir2\")\n",
      "\n",
      "phrase_to_search = u\"cancer\"\n",
      "\n",
      "with ix.searcher() as searcher: \n",
      "    parser = QueryParser(\"content\", schema=ix.schema)\n",
      "\n",
      "    query = parser.parse( phrase_to_search )\n",
      "    results = searcher.search(query)\n",
      "\n",
      "    for hit in results:    \n",
      "        hit_encoding = (hit[\"encoding\"])\n",
      "\n",
      "        with codecs.open(hit[\"path\"], \"r\", hit_encoding) as fileobj:\n",
      "            filecontents  = fileobj.read()\n",
      "            hit_highlight = hit.highlights(\"content\", text=filecontents)\n",
      "            hit_title     = (hit[\"title\"])\n",
      "\n",
      "            print (type(hit_highlight), hit[\"title\"])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "    print(results.docs)\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "    res=results.top_n(5)\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q)\n",
      "results\n",
      "for r in results:\n",
      "    print(r)\n",
      "for r in results:\n",
      "    print(r.fields)\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    results\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results)\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "print(results)\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "print(results[0])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "print(len(results))\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(len(results))\n",
      "schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True))\n",
      "ix = index.create_in(\"indexdir2\", schema)\n",
      "writer = ix.writer()\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            textblock = node.find('textblock')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(textblock))\n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(len(results))\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "print(results[0])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[1])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "# with open('clinicaltrials.xml/clinicaltrials_xml/002/00280/NCT00280787.xml', 'r') as f:\n",
      "#     h=f.read()\n",
      "#     f.close()\n",
      "#     print(h)\n",
      "with open('clinicaltrials.xml/clinicaltrials_xml/002/00280/NCT00280787.xml', 'r') as f:\n",
      "    h=f.read()\n",
      "    f.close()\n",
      "    print(h)\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os, os.path\n",
      "from whoosh import index\n",
      "from whoosh.index import open_dir\n",
      "from whoosh.fields import Schema, ID, TEXT, STORED\n",
      "from whoosh.qparser import QueryParser\n",
      "from whoosh.query import *\n",
      "import tarfile\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "import xml.etree.cElementTree as et\n",
      "import codecs\n",
      "# Creates directory: indexdir\n",
      "if not os.path.exists(\"indexdir2\"):\n",
      "   os.mkdir(\"indexdir2\")\n",
      "# Define schema - may have forgotten something. To add to query-able schema, define variable as \n",
      "# TEXT(stored=True)\n",
      "\n",
      "schema =  Schema(url=ID(stored=True), \n",
      "                 title=TEXT(stored=True), \n",
      "                 detailed_description=TEXT(stored=True),\n",
      "                 brief_summary = TEXT(stored=True),\n",
      "                 gender=TEXT(stored=True),\n",
      "                 maximum_age=TEXT(stored=True),\n",
      "                 minimum_age=TEXT(stored=True))\n",
      "\n",
      "\n",
      "ix = index.create_in(\"indexdir2\", schema)\n",
      "writer = ix.writer()\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "# count=0\n",
      "# for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "#     for file in files:\n",
      "#         #print os.path.join(subdir, file)\n",
      "#         filepath = subdir + os.sep + file\n",
      "\n",
      "#         if filepath.endswith(\".xml\"):\n",
      "#             count+=1\n",
      "# count\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        \n",
      "        #  If attributes were added to the schema, assign variable to node.attrib.get(attribute)\n",
      "        #  and append this attribute to writer.add_document\n",
      "        \n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.attrib.get('official_title')\n",
      "            detailed_description = node.attrib.get('detailed_description')\n",
      "            brief_summary = node.attrib.get('brief_summary')\n",
      "            gender= node.attrib.get('gender')\n",
      "            maximum_age=node.attrib.get('maximum_age')\n",
      "            minimum_age=node.attrib.get('minimum_age')\n",
      "            \n",
      "            writer.add_document(url=url, \n",
      "                                title=official_title, \n",
      "                                detailed_description= detailed_description,\n",
      "                                brief_summary=brief_summary,\n",
      "                                gender=gender,\n",
      "                                maximum_age=maximum_age,\n",
      "                                minimum_age=minimum_age)\n",
      "            \n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"detailed_description\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"url\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"url\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "# Define schema - may have forgotten something. To add to query-able schema, define variable as \n",
      "# TEXT(stored=True)\n",
      "\n",
      "schema =  Schema(url=ID(stored=True), \n",
      "                 title=TEXT(stored=True), \n",
      "                 detailed_description=TEXT(stored=True),\n",
      "                 brief_summary = TEXT(stored=True),\n",
      "                 gender=TEXT(stored=True),\n",
      "                 maximum_age=TEXT(stored=True),\n",
      "                 minimum_age=TEXT(stored=True))\n",
      "\n",
      "\n",
      "ix = index.create_in(\"indexdir2\", schema)\n",
      "writer = ix.writer()\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "# count=0\n",
      "# for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "#     for file in files:\n",
      "#         #print os.path.join(subdir, file)\n",
      "#         filepath = subdir + os.sep + file\n",
      "\n",
      "#         if filepath.endswith(\".xml\"):\n",
      "#             count+=1\n",
      "# count\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        \n",
      "        #  To \n",
      "        \n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            brief_summary = node.find('brief_summary')\n",
      "            gender = node.find('gender')\n",
      "            maximum_age = node.find('maximum_age')\n",
      "            minimum_age = node.find('minimum_age')\n",
      "            \n",
      "            writer.add_document(url=url, \n",
      "                                title=getvalueofnode(official_title), \n",
      "                                detailed_description= getvalueofnode(detailed_description),\n",
      "                                brief_summary=getvalueofnode(brief_summary),\n",
      "                                gender=getvalueofnode(gender),\n",
      "                                maximum_age=getvalueofnode(maximum_age),\n",
      "                                minimum_age=getvalueofnode(minimum_age)\n",
      "                                )\n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"detailed_description\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"detailed_description\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"brief_summary\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"brief_summary\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"brief_summary\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "# Define schema\n",
      "schema =  Schema(url=ID(stored=True), \n",
      "                 title=TEXT(stored=True), \n",
      "                 content=TEXT(stored=True)\n",
      "                 )\n",
      "ix = index.create_in(\"indexdir\", schema)\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "# count=0\n",
      "# for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "#     for file in files:\n",
      "#         #print os.path.join(subdir, file)\n",
      "#         filepath = subdir + os.sep + file\n",
      "\n",
      "#         if filepath.endswith(\".xml\"):\n",
      "#             count+=1\n",
      "# count\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        \n",
      "        #  To \n",
      "        \n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(detailed_description))\n",
      "writer.commit()\n",
      "# Creates directory: indexdir\n",
      "if not os.path.exists(\"indexdir2\"):\n",
      "   os.mkdir(\"indexdir2\")\n",
      "# Define schema\n",
      "schema =  Schema(url=ID(stored=True), \n",
      "                 title=TEXT(stored=True), \n",
      "                 content=TEXT(stored=True)\n",
      "                 )\n",
      "ix = index.create_in(\"indexdir\", schema)\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "# count=0\n",
      "# for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "#     for file in files:\n",
      "#         #print os.path.join(subdir, file)\n",
      "#         filepath = subdir + os.sep + file\n",
      "\n",
      "#         if filepath.endswith(\".xml\"):\n",
      "#             count+=1\n",
      "# count\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        \n",
      "        #  To \n",
      "        \n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(detailed_description))\n",
      "writer.commit()\n",
      "schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True))\n",
      "ix = index.create_in(\"indexdir\", schema)\n",
      "writer = ix.writer()\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        \n",
      "        #  To \n",
      "        \n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(detailed_description))\n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"brief_summary\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "# Creates directory: indexdir\n",
      "if not os.path.exists(\"indexdir3\"):\n",
      "   os.mkdir(\"indexdir3\")\n",
      "schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True))\n",
      "\n",
      "ix = index.create_in(\"indexdir3\", schema)\n",
      "writer = ix.writer()\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "# count=0\n",
      "# for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "#     for file in files:\n",
      "#         #print os.path.join(subdir, file)\n",
      "#         filepath = subdir + os.sep + file\n",
      "\n",
      "#         if filepath.endswith(\".xml\"):\n",
      "#             count+=1\n",
      "# count\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        \n",
      "        #  To \n",
      "        \n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(detailed_description))\n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"brief_summary\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "# Creates directory: indexdir\n",
      "if not os.path.exists(\"indexdir3\"):\n",
      "   os.mkdir(\"indexdir3\")\n",
      "schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True))\n",
      "\n",
      "ix = index.create_in(\"indexdir3\", schema)\n",
      "writer = ix.writer()\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "# count=0\n",
      "# for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "#     for file in files:\n",
      "#         #print os.path.join(subdir, file)\n",
      "#         filepath = subdir + os.sep + file\n",
      "\n",
      "#         if filepath.endswith(\".xml\"):\n",
      "#             count+=1\n",
      "# count\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        \n",
      "        #  To \n",
      "        \n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(detailed_description))\n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0])\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        \n",
      "        #  To \n",
      "        \n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(detailed_description))\n",
      "writer.commit()\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "writer = ix.writer()\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        \n",
      "        #  To \n",
      "        \n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(detailed_description))\n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0])\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0])\n",
      "ix = open_dir(\"indexdir3\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True))\n",
      "\n",
      "ix = index.create_in(\"indexdir2\", schema)\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "writer = ix.writer()\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        \n",
      "        #  To \n",
      "        \n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            writer.add_document(url=url, title=getvalueofnode(official_title), content= getvalueofnode(detailed_description))\n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "# Creates directory: indexdir\n",
      "if not os.path.exists(\"indexdir2\"):\n",
      "   os.mkdir(\"indexdir2\")\n",
      "schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True))\n",
      "\n",
      "ix = index.create_in(\"indexdir2\", schema)\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "# count=0\n",
      "# for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "#     for file in files:\n",
      "#         #print os.path.join(subdir, file)\n",
      "#         filepath = subdir + os.sep + file\n",
      "\n",
      "#         if filepath.endswith(\".xml\"):\n",
      "#             count+=1\n",
      "# count\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "writer = ix.writer()\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            writer.add_document(url=url, \n",
      "                                title=getvalueofnode(official_title), \n",
      "                                content= getvalueofnode(detailed_description))\n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"detailed_description\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"title\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "ix = open_dir(\"indexdir2\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "# Creates directory: indexdir\n",
      "if not os.path.exists(\"indexdir\"):\n",
      "   os.mkdir(\"indexdir\")\n",
      "schema =  Schema(url=ID(stored=True), title=TEXT(stored=True), content=TEXT(stored=True))\n",
      "\n",
      "ix = index.create_in(\"indexdir\", schema)\n",
      "# tar = tarfile.open(\"clinicaltrials_xml.tar.gz\", \"r:gz\")\n",
      "# members=tar.getmembers()\n",
      "# for member in members:\n",
      "#     tar.extractfile(member)\n",
      "# count=0\n",
      "# for subdir, dirs, files in os.walk('clinicaltrials.xml'):\n",
      "#     for file in files:\n",
      "#         #print os.path.join(subdir, file)\n",
      "#         filepath = subdir + os.sep + file\n",
      "\n",
      "#         if filepath.endswith(\".xml\"):\n",
      "#             count+=1\n",
      "# count\n",
      "#  This function iterates through cilinicaltrials.xml parent directory to all files in all \n",
      "#  subdirectories. \n",
      "\n",
      "writer = ix.writer()\n",
      "\n",
      "for subdir, dirs, files in os.walk('clinicaltrials.xml/clinicaltrials_xml/002'):\n",
      "    for file in files:\n",
      "        #print os.path.join(subdir, file)\n",
      "        filepath = subdir + os.sep + file\n",
      "        parser = et.XMLParser(encoding=\"utf-8\")\n",
      "        parsedXML = et.parse(filepath, parser=parser)\n",
      "        def getvalueofnode( node ):\n",
      "            return node.text if node is not None else None\n",
      "        for node in parsedXML.getroot():\n",
      "            url = node.attrib.get('url')\n",
      "            official_title = node.find('official_title')\n",
      "            detailed_description = node.find('detailed_description')\n",
      "            writer.add_document(url=url, \n",
      "                                title=getvalueofnode(official_title), \n",
      "                                content= getvalueofnode(detailed_description))\n",
      "writer.commit()\n",
      "ix = open_dir(\"indexdir\")\n",
      "qp = QueryParser(\"content\", schema=ix.schema)\n",
      "q = qp.parse(u\"drugs\")\n",
      "\n",
      "with ix.searcher() as s:\n",
      "    results = s.search(q, limit=10)\n",
      "    print(results[0:10])\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "%history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
